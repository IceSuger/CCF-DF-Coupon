version		feature		preprocess	online_auc
0.23		3,4,8,9,10,12,14,17		
0.24 		3,4,8,9,10,12,14,17,20	MaxAbsScale,OneHot	0.53825059 
0.25		尝试先多项式化，然后把原本的特征3 8 9 14的列号挑出来，也哑编码，最后一起MaxAbsScale   0.57818376 
1.0

-------------
1.2		3,4,8,9,10,12,14,17,20	xgb_no scale no dumm	
0.57312655 
params = {
        "objective": "binary:logistic",
        "booster" : "gbtree",
        "eval_metric": "auc",
        "eta": 0.1,
        "max_depth": 5,
        "subsample": 0.8,
        "colsample_bytree": 0.8,
        "silent": 0,
        "seed": 1,
    }
num_boost_round = 20
------------------
v1.3
全都和1.2相同，只是1.3不做poly了。结果线上 0.60074065 
-----------------
v1.4
xgb1 = XGBClassifier(
     learning_rate =0.1,
     n_estimators=500, #好像在eta 0.1时测出来是最好为417
     max_depth=5,
     min_child_weight=1,
     gamma=0,
     subsample=0.8,
     colsample_bytree=0.8,
     objective= 'binary:logistic',
     nthread=4,
     scale_pos_weight=1,
     seed=27)
	 这时候找到的最佳n_estimators = 417.（当时的test-auc:0.998426+小量）
	 
尝试参数xgb2 = XGBClassifier(
     learning_rate =0.05,
     n_estimators=1000, #好像在eta 0.1时测出来是最好为417
     max_depth=7,
     min_child_weight=1,
     gamma=0,
     subsample=0.8,
     colsample_bytree=0.8,
     objective= 'binary:logistic',
     nthread=4,
     scale_pos_weight=1,
     seed=27)
	 这时候找到的最佳n_estimators = 434。（当时test-auc:0.998435+2.08864e-5）
但用第二套参数预测，提交之后，线上成绩只有0.58551380 
---------
v1.5
1. 首先尝试仿照7月集合和全部训练集的关系，构造六月验证集。因为7月的全部userid几乎都在训练集中出现过，那么对六月的验证集，算平均auc时就只考虑userid在X_nojun这一训练集中出现过的条目。
结果是 还他妈不如之前的呢。本来0.494的，现在0.489了，线上可是0.58551380啊。
------------
v1.6
params = {
        "objective": "binary:logistic",
        "booster" : "gbtree",
        "eval_metric": "auc",
        "eta": 0.05,
        "max_depth": 5,
        "subsample": 0.8,
        "colsample_bytree": 0.8,
        "silent": 0,
        "nthread":4,
        "seed": 27,
    }
num_boost_round = 100

---------
v1.7 这个版本生成的预测结果，用了和1.6一样的参数。而特征新加了15 16 23 24 25.
线上0.62250179 
---------
v1.8 
params = {
        "objective": "binary:logistic",
        "booster" : "gbtree",
        "eval_metric": "auc",
        "eta": 0.05,
        "max_depth": 5,
        "subsample": 0.8,
        "colsample_bytree": 0.8,
        "silent": 0,
        "nthread":4,
        "seed": 27,
    }
num_boost_round = 130
特征和1.7一样，只是改了num_boost_round，现在只能通过提交看线上成绩来调参了....线下调参没有什么好的办法
0.61848929 
-------
v1.9
尝试n=90	线上得分：
0.62230576 
--------
v1.10
这个版本打算尝试加入特征13，看看效果如何
用n100,n90分别生成两个。结果分别是：n100为0.61917062 ，n90为0.61958875 
特征13有毒啊！？
-----------
v1.11
去掉特征13，尝试了n=96
线上0.62252029 

尝试了改树最大深度，从5改为4，其他参数没变
线上0.61786008
线下Direct Mean auc is:  0.49450479275
加上用户id的限制后，direct：0.489557371452
-----------
v1.12
尝试了改树最大深度，从4改为6，其他参数没变
线上0.62197084 
线下Direct Mean auc is:  0.494429170496
加上用户id的限制后，direct：0.489466482791
------------
v1.13
发现了一个大问题：用xgb是在把处理特征的过程独立成pre_preprocess.py之后。而在这个处理特征的过程中，把训练集里的字段2的空值都填上了0.但是在bigbird中没有对字段11的标记规则进行修改，仍然是对字段2和6同时非空的都标记为1.这直接导致，后来的正例只比反例少一点，二者远不像之前那么不平衡了。当然这只是统计上的规律，关键的是，这他妈的标记是错的啊兄弟！
现在把bigbird里相应的标记规则改成了6非空，2大于0.
那么我们的xgb就要重新面对训练类别不平衡的问题了。
在这个版本中没有对这件事做处理，先用和上个版本一样的参数跑一边看看效果吧。
线上：0.54426046 

等出来结果之后，有如下一些考虑：
1.如果结果有提升，那么根据f_score，尝试去掉importances中占后5%的特征，再训练一个提交；
2.如果结果下降了，那么可能是类别不平衡引起的。那么可以看看特征重要性占的比重，对比一下标错11字段时的特征重要性比重。看看有没有什么发现。
3.无论结果提升还是下降，都可以考虑加上类别平衡，并且尝试不同的weight：0.043或0.1？

另外，根据刚才在网上看的时候的想法。会不会因为特征1的存在，导致了许多训练集中没有的商户的结果被预测错？这一点在1字段有较高重要性的时候尤其有可能啊。
那么：
1. 先重新统计一下，看看测试集合训练集里1字段的交叉率有多少？
2. 尝试去掉特征1，重新训练，提交结果。
3. 注意一点。有好几个统计量特征，也是基于对字段1来统计出来的，也就是很多反应商户特点的特征，在商户不在训练集中时，肯定是瞎jb预测的啊。
--1. OK，看过了。交叉的1558个，测试集里一共1559个。去他妈的。全猜错了。
------------------
v1.14
用0.043的weight做了平衡，线上0.54441005 。比起没平衡的，只是有一丁点提高。
---------
v1.15
尝试了LR，用错误标记训练，结果也不理想：0.54159526 
文件夹中现在那个v1.15_balanced.csv，是用xgb,在用正负类别比例做weight平衡训练集之后得出的结果。我猜它和0.043的不会有多大差别，就不浪费这次提交机会了。这次改为提交v1.16的了。过了12点再提交这个1.15的。
---------
v1.16
0.重新按错误标记进行训练
1.对类别做了平衡
2.根据错误标记下训练出来的xgb给出的fscore，选取特征1,3,8,9,10,12,14,15,16,17,20,23,24,25
线上：0.61855547 
未平衡的版本
线上：0.62072104 
-------------
v1.17
尝试更改预处理策略，不再填充空值，尤其是特征4

-------------
v2.0
重新按正确标记预处理了特征，并用正确标记训练模型。
线上：0.57034938
线下 0.495（从此开始，线下都是用15天以内用券消费才算正例，来进行评判的了）
----------
v2.1
还是按错误标记预处理和训练吧。不过现在对空值从头到尾都不处理，直接扔进去训练。
线上：0.57？？？
线下：0.4952260
-------
v2.2
现在带上了特征18 19 21 22.
线上：0.56876597
线下：0.4952624
------------
v2.3
去掉特征18 19 21 22.保持类别不平衡。训练和预处理都是错误标记。
反思一下2.2和2.3的结果，为什么还是不到0.6？终于找到了原因，现在在训练中标记又变成正确的了。为啥？因为：在预处理的时候，现在不管空值了，也就是说字段2在训练的时候，空值任然为空，那么在训练前的标记过程中，还是只标出了正确的正例。那么效果自然就是0.56 0.57这种水平了。
现在改掉了。并且去掉18 19 21 22生成了v2.3
线上：*******
线下：0.49524407149
------
v2.4（王者五提交）
带着18 19 21 22.又生成了v2.4。其他部分和2.3相同。
线上：0.60934825 

-------
v2.5
对线上部分，包括训练集和测试集，都重新用正确标记（用券消费的，不区分15天的事）处理了。带着18~22的。
线上：0.60795148
线下：0.495175776013
同时用王者五提交了一个用v1.11和v2.3 ensemble的结果。
线上：0.61928291 
---------
v2.6
去掉特征13，带着特征18 19 21 22
线上：0.61292102
同时用王者五提交了一个v1.11，v1.9 v2.3按7:2:1融合的结果
线上：0.61928430
-----------
v3.0（icesugar）
去掉13 18 19 21 22。现在应该是除了空值处理方式，其他的都和0.62252029的时候一样了吧？
线下：0.495274134691
线上：0.59966988
一样个屁！妈的到底是哪不对啊！
这么看来18 19 21 22是有意义的啊！！
-----------
v3.1（王者五）
加了26 27 28 29
线下：0.495174895319
线上：0.60967348 
结合3.0的线上结果来看，26 27 28 29也是有意义的啊！！
操啊！我他妈到底是改了什么东西啊？？
-------------------
v3.2（icesugar）
用了特征0,1,3,4,8,9,10,12,14,15,16,17,20,23,24,25,26,27,28,29
现在只能猜测是因为特征14的空值填充策略导致了结果那么大的差异了。也算能解释，毕竟特征重要性排在第二的特征。
现在对14进行空值填充：0.（只用对训练集做，因为测试集这个字段都非空）
线上：0.60967348 
线下：0.495174895319
-----------
v3.3（王者五）
同3.2，区别在于用35填充字段14.（这可就真和0.62252的时候差不多了啊！）
线上：0.60967348 
线下：0.495174895319
-----------
v3.4
把18 19 21 22也带上了，同时增加n_estimator到130
线下：0.495209449846
线上：0.61435227
------------
v3.5（王者五）
n维持在96，同样加了上述四个特征
线下：0.495175764513
线上：0.61197546 
---------------
v3.6
现在所有特征都已经按最佳方式处理了！得分再不上0.63，直播吃翔！！
这个版本中，迭代轮数num_boost_round = 130
线下：0.495209448527
线上：0.62091423
----------------
v3.7（王者五）
同上，区别在于num_boost_round = 96
线下：0.495175799503
线上：0.61611104 
------------
v3.8
迭代轮数n=150（2016 10 31 凌晨0点由icesugar提交）
线下：0.495209449523
线上：

迭代轮数n=200
线下：0.495360069452
线上：

迭代轮数n=250
线下：0.495512352072
线上：

迭代轮数n=350
线下：0.495566137059
线上：

迭代轮数n=500
线下：0.49589757579
线上：0.61031058
看来这个轮数确实过高了

迭代轮数n=1000
线下：0.495818139107
-------------
v3.9（王者五）
迭代轮数96。特征和v1.11一样：0,1,3,4,8,9,10,12,14,15,16,17,20,23,24,25
线下：0.495232629657
线上：0.61527324
这他妈就很奇怪了。到底是哪里和v1.11不一样啊？？？？为啥低了这么多？？
-----------
v3.10（王者五）
对比发现，offline14和offline7的字段14 17 23 24 25还是有不同。我他妈是不想去改程序了。直接把版本7中的这些字段拿过来了，和版本14的其他字段一起拼出来一个版本15.
训练集如此，测试集当然有着一样的问题，那就用一样的方式解决了，得到了test15。
用版本15的数据集做了结果，n=150。
线下：0.495161574927
线上：